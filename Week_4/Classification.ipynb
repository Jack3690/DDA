{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM8b9FXlDCdhxGB3T7YFrwz"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JzU_p3ZK-3-S","colab_type":"text"},"source":["#**Classification**\n","In classification, the predictions are from a fixed set of classes, whereas in regression the prediction typically corresponds to a continuum of possible values.\n","In regression, we measure accuracy by looking at the size of the differences between the predicted values and the actual values. In contrast, in classification problems a prediction can either be correct or incorrect. This makes measuring the accuracy of our model a lot simpler.\n","\n","In terms of implementation using decision trees, there is very little difference between classification and regression. The only notable difference is that our targets are classes rather than real values. When calculating the accuracy, we check whether the predicted class matches as the actual class.\n","\n","A note on decision tree regression\n","In decision tree regression, the possible outputs are a finite set of values that correspond to the number of leaves/end points in the tree. Ideally we want as many points as possible to give a good approximation of the 'continuous' parameter space, whilst avoiding overfitting.\n","\n"]},{"cell_type":"code","metadata":{"id":"nNM5hez8-vTj","colab_type":"code","colab":{}},"source":["from google.colab import files\n","uploaded = files.upload()  #upload galaxy_catalogue.npy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ANDnRkvvILVv","colab_type":"code","colab":{}},"source":["import numpy as np\n","data = np.load('galaxy_catalogue.npy')\n","for name, value in zip(data.dtype.names, data[0]):  # Gives you a description of data  \n","  print('{:10} {:.6}'.format(name, value))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pt4pzjy3Iv7T","colab_type":"code","colab":{}},"source":["# Split data into training and testing set\n","\n","fraction=0.7 # Earlier we split equally between training set and testing set lets try different fraction\n","\n","split=int(data.shape[0]*fraction)\n","# Create Train_data and Test_data\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S54WoczLJtd3","colab_type":"text"},"source":["The features that we will be using to do our galaxy classification are colour index, adaptive moments, eccentricities and concentrations. These features are provided as part of the SDSS catalogue.\n","\n","We briefly describe these below. Further information how they are calculated can be found here:http://skyserver.sdss.org/dr7/en/help/docs/algorithm.asp\n","\n","Next, we generate features and targets for the decision tree.\n","\n","The generate_features_targets function is mostly complete. However, you need to calculate the concentration values for the u, r and z filters.\n","\n","Your task is to calculate the concentration for each filter from the 50% and 90% Petrosian radius measurements:\n","\n","$conc$= $petro$ $R_{50}$/$petro$ $R_{90}$\n"," \n","\n","As described earlier, data has the following fields:\n","\n","**colours**: u-g, g-r, r-i, and i-z;<br>\n","**eccentricity**: ecc<br>\n","**4th adaptive moments**: m4_u, m4_g, m4_r, m4_i, and m4_z;<br>\n","**50% Petrosian**: petroR50_u, petroR50_r, petroR50_z;<br>\n","**90% Petrosian**: petroR90_u, petroR90_r, petroR90_z."]},{"cell_type":"code","metadata":{"id":"qG0duPIvM3xL","colab_type":"code","colab":{}},"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","def generate_features_targets(data):\n","  # complete the function by calculating the concentrations\n","\n","  targets = data['class']\n","  # populate features \n","  features = np.empty(shape=(len(data), 13))\n","  features[:, 0] = data['u-g']     # Hint\n","  features[:, 1] = \n","  features[:, 2] = \n","  features[:, 3] = \n","  features[:, 4] = \n","  features[:, 5] = \n","  features[:, 6] = \n","  features[:, 7] = \n","  features[:, 8] = \n","  features[:, 9] = \n","\n","  # fill the remaining 3 columns with concentrations in the u, r and z filters\n","  # concentration in u filter\n","  features[:, 10] = data['petroR50_u']/data['petroR90_u']\n","  # concentration in r filter\n","  features[:, 11] = \n","  # concentration in z filter\n","  features[:, 12] = \n","\n","  return features, targets\n","\n","Train_features, Train_targets = generate_features_targets(Train_data)\n","\n","Test_features, Test_targets = generate_features_targets(Test_data)\n","\n","# Print the shape of each array to check the arrays are the correct dimensions. \n","print(\"Features shape:\", Train_features.shape)\n","print(\"Targets shape:\", Train_targets.shape)\n","\n","# initialize model\n","dtr = DecisionTreeClassifier()   #Its a Classifier now\n","# train the model\n","\n","# make predictions using the test features\n","predictions = \n","# print out the first 4 predicted morphology\n","print(predictions[:4])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CdpVPj1zPa8m","colab_type":"text"},"source":["Your task is to complete the calculate_accuracy function. The function should calculate the accuracy: the fraction of predictions that are correct (i.e. the model score):\n","\n","accuracy = **no_of_correct_predictions/no of predictions**\n"," \n","The function takes two arguments;\n","\n","predicted: an array of the predicted class for each galaxy.\n","actual: an array of the actual class for each galaxy.\n","The return value should be a float (between 0 and 1)."]},{"cell_type":"code","metadata":{"id":"zikqKqWAQLp2","colab_type":"code","colab":{}},"source":["#Complete the function calculate_accuracy using the above mentioned formula\n","def calculate_accuracy(predicted, actual):\n","  \n","\n","print(calculate_accuracy(predictions,Test_targets))  "],"execution_count":null,"outputs":[]}]}